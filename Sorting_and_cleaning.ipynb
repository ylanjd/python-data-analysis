{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/futureCodersSE/working-with-data/blob/main/Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CVoh0pMzW0l"
   },
   "source": [
    "# Sorting and cleaning \n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "In order to effectively analyse a dataset, often we need to prepare it first. \n",
    "Before a dataset is ready to be analysed we might need to:  \n",
    "\n",
    "* sort the data (can be a series or dataframe)  \n",
    "* remove any NaN values or drop NA values   \n",
    "* remove duplicate records (identical rows)  \n",
    "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
    "\n",
    "## Sorting the data  \n",
    "---\n",
    "\n",
    "\n",
    "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
    "\n",
    "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
    "\n",
    "By default `sort_values()` sorts into ascending order.\n",
    "\n",
    "* sort by a single column e.g.\n",
    "  * `df.sort_values(\"Make\") `\n",
    "* sort by multiple columns e.g. \n",
    "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
    "    * this sorts by Model, then my Make \n",
    "* sort in *descending* order\n",
    "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
    "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
    "\n",
    "Dataframes are mostly immutable, changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
    "\n",
    "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
    "`df` *original dataframe, df, will be as it was - unsorted* \n",
    "\n",
    "To split the dataframe after sorting, do this in the same instruction, e.g.:\n",
    "\n",
    "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
    "\n",
    "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
    "\n",
    "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
    "\n",
    "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANKknIx8E-hN"
   },
   "source": [
    "### Exercise 1 - get data, sort by happiness score \n",
    "---\n",
    "\n",
    "Read data from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
    "\n",
    "Display first 5 rows of data  \n",
    "\n",
    "The data is currently sorted by Happiness Rank...\n",
    "*  sort the data by Happiness Score in ascending order\n",
    "*  display sorted table\n",
    "\n",
    "**Test output**:  \n",
    "The lowest score (displayed first) is 2.839, Togo  \n",
    "The highest score (displayed last) is 7.587, Switzerland  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "      <th>Happiness Rank</th>\n",
       "      <th>Happiness Score</th>\n",
       "      <th>Standard Error</th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Family</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "      <th>Freedom</th>\n",
       "      <th>Trust (Government Corruption)</th>\n",
       "      <th>Generosity</th>\n",
       "      <th>Dystopia Residual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>1</td>\n",
       "      <td>7.587</td>\n",
       "      <td>0.03411</td>\n",
       "      <td>1.39651</td>\n",
       "      <td>1.34951</td>\n",
       "      <td>0.94143</td>\n",
       "      <td>0.66557</td>\n",
       "      <td>0.41978</td>\n",
       "      <td>0.29678</td>\n",
       "      <td>2.51738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>2</td>\n",
       "      <td>7.561</td>\n",
       "      <td>0.04884</td>\n",
       "      <td>1.30232</td>\n",
       "      <td>1.40223</td>\n",
       "      <td>0.94784</td>\n",
       "      <td>0.62877</td>\n",
       "      <td>0.14145</td>\n",
       "      <td>0.43630</td>\n",
       "      <td>2.70201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>3</td>\n",
       "      <td>7.527</td>\n",
       "      <td>0.03328</td>\n",
       "      <td>1.32548</td>\n",
       "      <td>1.36058</td>\n",
       "      <td>0.87464</td>\n",
       "      <td>0.64938</td>\n",
       "      <td>0.48357</td>\n",
       "      <td>0.34139</td>\n",
       "      <td>2.49204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>4</td>\n",
       "      <td>7.522</td>\n",
       "      <td>0.03880</td>\n",
       "      <td>1.45900</td>\n",
       "      <td>1.33095</td>\n",
       "      <td>0.88521</td>\n",
       "      <td>0.66973</td>\n",
       "      <td>0.36503</td>\n",
       "      <td>0.34699</td>\n",
       "      <td>2.46531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>North America</td>\n",
       "      <td>5</td>\n",
       "      <td>7.427</td>\n",
       "      <td>0.03553</td>\n",
       "      <td>1.32629</td>\n",
       "      <td>1.32261</td>\n",
       "      <td>0.90563</td>\n",
       "      <td>0.63297</td>\n",
       "      <td>0.32957</td>\n",
       "      <td>0.45811</td>\n",
       "      <td>2.45176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>154</td>\n",
       "      <td>3.465</td>\n",
       "      <td>0.03464</td>\n",
       "      <td>0.22208</td>\n",
       "      <td>0.77370</td>\n",
       "      <td>0.42864</td>\n",
       "      <td>0.59201</td>\n",
       "      <td>0.55191</td>\n",
       "      <td>0.22628</td>\n",
       "      <td>0.67042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Benin</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>155</td>\n",
       "      <td>3.340</td>\n",
       "      <td>0.03656</td>\n",
       "      <td>0.28665</td>\n",
       "      <td>0.35386</td>\n",
       "      <td>0.31910</td>\n",
       "      <td>0.48450</td>\n",
       "      <td>0.08010</td>\n",
       "      <td>0.18260</td>\n",
       "      <td>1.63328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Syria</td>\n",
       "      <td>Middle East and Northern Africa</td>\n",
       "      <td>156</td>\n",
       "      <td>3.006</td>\n",
       "      <td>0.05015</td>\n",
       "      <td>0.66320</td>\n",
       "      <td>0.47489</td>\n",
       "      <td>0.72193</td>\n",
       "      <td>0.15684</td>\n",
       "      <td>0.18906</td>\n",
       "      <td>0.47179</td>\n",
       "      <td>0.32858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>157</td>\n",
       "      <td>2.905</td>\n",
       "      <td>0.08658</td>\n",
       "      <td>0.01530</td>\n",
       "      <td>0.41587</td>\n",
       "      <td>0.22396</td>\n",
       "      <td>0.11850</td>\n",
       "      <td>0.10062</td>\n",
       "      <td>0.19727</td>\n",
       "      <td>1.83302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Togo</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "      <td>158</td>\n",
       "      <td>2.839</td>\n",
       "      <td>0.06727</td>\n",
       "      <td>0.20868</td>\n",
       "      <td>0.13995</td>\n",
       "      <td>0.28443</td>\n",
       "      <td>0.36453</td>\n",
       "      <td>0.10731</td>\n",
       "      <td>0.16681</td>\n",
       "      <td>1.56726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country                           Region  Happiness Rank  \\\n",
       "0    Switzerland                   Western Europe               1   \n",
       "1        Iceland                   Western Europe               2   \n",
       "2        Denmark                   Western Europe               3   \n",
       "3         Norway                   Western Europe               4   \n",
       "4         Canada                    North America               5   \n",
       "..           ...                              ...             ...   \n",
       "153       Rwanda               Sub-Saharan Africa             154   \n",
       "154        Benin               Sub-Saharan Africa             155   \n",
       "155        Syria  Middle East and Northern Africa             156   \n",
       "156      Burundi               Sub-Saharan Africa             157   \n",
       "157         Togo               Sub-Saharan Africa             158   \n",
       "\n",
       "     Happiness Score  Standard Error  Economy (GDP per Capita)   Family  \\\n",
       "0              7.587         0.03411                   1.39651  1.34951   \n",
       "1              7.561         0.04884                   1.30232  1.40223   \n",
       "2              7.527         0.03328                   1.32548  1.36058   \n",
       "3              7.522         0.03880                   1.45900  1.33095   \n",
       "4              7.427         0.03553                   1.32629  1.32261   \n",
       "..               ...             ...                       ...      ...   \n",
       "153            3.465         0.03464                   0.22208  0.77370   \n",
       "154            3.340         0.03656                   0.28665  0.35386   \n",
       "155            3.006         0.05015                   0.66320  0.47489   \n",
       "156            2.905         0.08658                   0.01530  0.41587   \n",
       "157            2.839         0.06727                   0.20868  0.13995   \n",
       "\n",
       "     Health (Life Expectancy)  Freedom  Trust (Government Corruption)  \\\n",
       "0                     0.94143  0.66557                        0.41978   \n",
       "1                     0.94784  0.62877                        0.14145   \n",
       "2                     0.87464  0.64938                        0.48357   \n",
       "3                     0.88521  0.66973                        0.36503   \n",
       "4                     0.90563  0.63297                        0.32957   \n",
       "..                        ...      ...                            ...   \n",
       "153                   0.42864  0.59201                        0.55191   \n",
       "154                   0.31910  0.48450                        0.08010   \n",
       "155                   0.72193  0.15684                        0.18906   \n",
       "156                   0.22396  0.11850                        0.10062   \n",
       "157                   0.28443  0.36453                        0.10731   \n",
       "\n",
       "     Generosity  Dystopia Residual  \n",
       "0       0.29678            2.51738  \n",
       "1       0.43630            2.70201  \n",
       "2       0.34139            2.49204  \n",
       "3       0.34699            2.46531  \n",
       "4       0.45811            2.45176  \n",
       "..          ...                ...  \n",
       "153     0.22628            0.67042  \n",
       "154     0.18260            1.63328  \n",
       "155     0.47179            0.32858  \n",
       "156     0.19727            1.83302  \n",
       "157     0.16681            1.56726  \n",
       "\n",
       "[158 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true'\n",
    "happiness = pd.read_excel(url)\n",
    "happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jkvFGvJtHXiH",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Happiness Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Togo</td>\n",
       "      <td>2.839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Burundi</td>\n",
       "      <td>2.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Syria</td>\n",
       "      <td>3.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Benin</td>\n",
       "      <td>3.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Rwanda</td>\n",
       "      <td>3.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>7.427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Norway</td>\n",
       "      <td>7.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>7.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>7.561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>7.587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>158 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country  Happiness Score\n",
       "157         Togo            2.839\n",
       "156      Burundi            2.905\n",
       "155        Syria            3.006\n",
       "154        Benin            3.340\n",
       "153       Rwanda            3.465\n",
       "..           ...              ...\n",
       "4         Canada            7.427\n",
       "3         Norway            7.522\n",
       "2        Denmark            7.527\n",
       "1        Iceland            7.561\n",
       "0    Switzerland            7.587\n",
       "\n",
       "[158 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "happy_sorted = happiness.sort_values(by = ['Happiness Score'], ascending=True)[['Country', 'Happiness Score']]\n",
    "happy_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_iomqRTH8LA"
   },
   "source": [
    "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
    "---\n",
    "\n",
    "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order \n",
    "2. display the first 5 rows of sorted data \n",
    "\n",
    "**Test output**:  \n",
    "Records 122, 127, 147, 100, 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "b7XalX7OK0u-",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Economy (GDP per Capita)</th>\n",
       "      <th>Health (Life Expectancy)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.09806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.01530</td>\n",
       "      <td>0.22396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.01604</td>\n",
       "      <td>0.22562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.06940</td>\n",
       "      <td>0.29707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.07120</td>\n",
       "      <td>0.34201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Economy (GDP per Capita)  Health (Life Expectancy)\n",
       "119                   0.00000                   0.09806\n",
       "156                   0.01530                   0.22396\n",
       "130                   0.01604                   0.22562\n",
       "143                   0.06940                   0.29707\n",
       "115                   0.07120                   0.34201"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness.sort_values(by = ['Economy (GDP per Capita)', 'Health (Life Expectancy)'], ascending=True)[['Economy (GDP per Capita)', 'Health (Life Expectancy)']].iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xfQ3cys4LHNc"
   },
   "source": [
    "### Exercise 3 - sorting in descending order \n",
    "---\n",
    " \n",
    "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
    "\n",
    "**Test output**:\n",
    "136, 117, 95, 101, 111 Country and Region columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3haPVvX7MCom",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>Angola</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Sudan</td>\n",
       "      <td>Sub-Saharan Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>Central and Eastern Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Greece</td>\n",
       "      <td>Western Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Iraq</td>\n",
       "      <td>Middle East and Northern Africa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Country                           Region\n",
       "136                  Angola               Sub-Saharan Africa\n",
       "117                   Sudan               Sub-Saharan Africa\n",
       "95   Bosnia and Herzegovina       Central and Eastern Europe\n",
       "101                  Greece                   Western Europe\n",
       "111                    Iraq  Middle East and Northern Africa"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happiness.sort_values(by = ['Freedom', 'Trust (Government Corruption)'], ascending=False)[['Country', 'Region']].tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqnAoELjMDs7"
   },
   "source": [
    "# Cleaning the data\n",
    "\n",
    "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
    "\n",
    "Techniques for data cleansing include:\n",
    "*  removing records with missing or null data (NaN, NA, \"\")\n",
    "*  removing duplicate rows (keeping just one, either the first or the last)\n",
    "\n",
    "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVqmfM5wk7NK"
   },
   "source": [
    "---\n",
    "\n",
    "## Removing NaN/Dropping NA values \n",
    "\n",
    "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
    "\n",
    "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
    "  `df.isnull().values.any()`  \n",
    "\n",
    "* check for NA/NaN/missing values in specific column  \n",
    "  `df[\"Make\"].isnull().values.any()`  \n",
    "\n",
    "* drop all rows that have NA/NaN values   \n",
    "  `df.dropna()`  \n",
    "\n",
    "* drop rows where NA/NaN values exist in specific columns  \n",
    "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DC65hEZGOKNL"
   },
   "source": [
    "### Exercise 4 - check for null values \n",
    "---\n",
    "\n",
    "1. read data from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv \n",
    "2. check if any NA values exist in the dataframe and print the result \n",
    "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n",
    "\n",
    "**Test output**:\n",
    "True\n",
    ".info shows median_salary, life_satisfaction, recycling_pct, population_size, number_of_jobs, area_size, no_of_houses all less than total rows (1071) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "U7LYkXDNVVc9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1071 entries, 0 to 1070\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   code               1071 non-null   object \n",
      " 1   area               1071 non-null   object \n",
      " 2   date               1071 non-null   object \n",
      " 3   median_salary      1049 non-null   float64\n",
      " 4   life_satisfaction  352 non-null    float64\n",
      " 5   mean_salary        1071 non-null   object \n",
      " 6   recycling_pct      860 non-null    object \n",
      " 7   population_size    1018 non-null   float64\n",
      " 8   number_of_jobs     931 non-null    float64\n",
      " 9   area_size          666 non-null    float64\n",
      " 10  no_of_houses       666 non-null    float64\n",
      " 11  borough_flag       1071 non-null   int64  \n",
      "dtypes: float64(6), int64(1), object(5)\n",
      "memory usage: 100.5+ KB\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv'\n",
    "housing = pd.read_csv(url)\n",
    "housing.isnull().values.any()\n",
    "housing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRBLm_bJVItu"
   },
   "source": [
    "### Exercise 5 - remove null values \n",
    "---\n",
    "\n",
    "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n",
    "2. remove all NA values across whole dataframe \n",
    "\n",
    "**Test output**:  \n",
    "1.  Row count reduced to 352 rows\n",
    "2.  Row count reduced to 267 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "OjZJNIC3QObK",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>28201.0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>33568</td>\n",
       "      <td>30</td>\n",
       "      <td>187029.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>3780.0</td>\n",
       "      <td>71079.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>30237.0</td>\n",
       "      <td>7.43</td>\n",
       "      <td>33062</td>\n",
       "      <td>34</td>\n",
       "      <td>357538.0</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>8675.0</td>\n",
       "      <td>139346.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>bexley</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>28638.0</td>\n",
       "      <td>7.42</td>\n",
       "      <td>31812</td>\n",
       "      <td>54</td>\n",
       "      <td>232774.0</td>\n",
       "      <td>78000.0</td>\n",
       "      <td>6429.0</td>\n",
       "      <td>95037.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>E09000005</td>\n",
       "      <td>brent</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>26772.0</td>\n",
       "      <td>7.11</td>\n",
       "      <td>29609</td>\n",
       "      <td>37</td>\n",
       "      <td>312245.0</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>4323.0</td>\n",
       "      <td>112083.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>E09000006</td>\n",
       "      <td>bromley</td>\n",
       "      <td>2011-12-01</td>\n",
       "      <td>28163.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>32863</td>\n",
       "      <td>50</td>\n",
       "      <td>310554.0</td>\n",
       "      <td>119000.0</td>\n",
       "      <td>15013.0</td>\n",
       "      <td>135036.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>E09000031</td>\n",
       "      <td>waltham forest</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>30298.0</td>\n",
       "      <td>7.46</td>\n",
       "      <td>32875</td>\n",
       "      <td>32</td>\n",
       "      <td>276700.0</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>3881.0</td>\n",
       "      <td>103029.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>E09000032</td>\n",
       "      <td>wandsworth</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>34501.0</td>\n",
       "      <td>7.65</td>\n",
       "      <td>45317</td>\n",
       "      <td>23</td>\n",
       "      <td>326474.0</td>\n",
       "      <td>147000.0</td>\n",
       "      <td>3522.0</td>\n",
       "      <td>146162.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>E09000033</td>\n",
       "      <td>westminster</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>43015.0</td>\n",
       "      <td>7.66</td>\n",
       "      <td>63792</td>\n",
       "      <td>22</td>\n",
       "      <td>255324.0</td>\n",
       "      <td>775000.0</td>\n",
       "      <td>2203.0</td>\n",
       "      <td>124509.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>E12000007</td>\n",
       "      <td>london</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>38146.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>52629</td>\n",
       "      <td>33</td>\n",
       "      <td>8908081.0</td>\n",
       "      <td>6148000.0</td>\n",
       "      <td>159471.0</td>\n",
       "      <td>3556161.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>E92000001</td>\n",
       "      <td>england</td>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>29856.0</td>\n",
       "      <td>7.71</td>\n",
       "      <td>37313</td>\n",
       "      <td>44</td>\n",
       "      <td>55977178.0</td>\n",
       "      <td>30493000.0</td>\n",
       "      <td>13303728.0</td>\n",
       "      <td>24172166.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           code                  area        date  median_salary  \\\n",
       "613   E09000002  barking and dagenham  2011-12-01        28201.0   \n",
       "614   E09000003                barnet  2011-12-01        30237.0   \n",
       "615   E09000004                bexley  2011-12-01        28638.0   \n",
       "616   E09000005                 brent  2011-12-01        26772.0   \n",
       "617   E09000006               bromley  2011-12-01        28163.0   \n",
       "...         ...                   ...         ...            ...   \n",
       "999   E09000031        waltham forest  2018-12-01        30298.0   \n",
       "1000  E09000032            wandsworth  2018-12-01        34501.0   \n",
       "1001  E09000033           westminster  2018-12-01        43015.0   \n",
       "1008  E12000007                london  2018-12-01        38146.0   \n",
       "1013  E92000001               england  2018-12-01        29856.0   \n",
       "\n",
       "      life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "613                7.05       33568            30         187029.0   \n",
       "614                7.43       33062            34         357538.0   \n",
       "615                7.42       31812            54         232774.0   \n",
       "616                7.11       29609            37         312245.0   \n",
       "617                7.50       32863            50         310554.0   \n",
       "...                 ...         ...           ...              ...   \n",
       "999                7.46       32875            32         276700.0   \n",
       "1000               7.65       45317            23         326474.0   \n",
       "1001               7.66       63792            22         255324.0   \n",
       "1008               7.58       52629            33        8908081.0   \n",
       "1013               7.71       37313            44       55977178.0   \n",
       "\n",
       "      number_of_jobs   area_size  no_of_houses  borough_flag  \n",
       "613          54000.0      3780.0       71079.0             1  \n",
       "614         147000.0      8675.0      139346.0             1  \n",
       "615          78000.0      6429.0       95037.0             1  \n",
       "616         115000.0      4323.0      112083.0             1  \n",
       "617         119000.0     15013.0      135036.0             1  \n",
       "...              ...         ...           ...           ...  \n",
       "999          88000.0      3881.0      103029.0             1  \n",
       "1000        147000.0      3522.0      146162.0             1  \n",
       "1001        775000.0      2203.0      124509.0             1  \n",
       "1008       6148000.0    159471.0     3556161.0             0  \n",
       "1013      30493000.0  13303728.0    24172166.0             0  \n",
       "\n",
       "[267 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.dropna(subset = ['life_satisfaction'])\n",
    "housing.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui8HF5z8SiK8"
   },
   "source": [
    "## Dropping duplicates\n",
    "---\n",
    "\n",
    "* To remove duplicate rows based on duplication of values in all columns  \n",
    "  `df.drop_duplicates()`  \n",
    "\n",
    "* To remove rows that have duplicate entries in a specified column  \n",
    "  `df.drop_duplicates(subset = ['Make'])`  \n",
    "\n",
    "* To remove rows that have duplicate entries in multiple columns  \n",
    "  `df.drop_duplicates(subset = ['Make', 'Model'])` \n",
    "\n",
    "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
    "  `df.drop_duplicates(keep='last')`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2Qf6uMxSb5t"
   },
   "source": [
    "### Exercise 6 - Removing duplicate entries \n",
    "---\n",
    "\n",
    "remove duplicate `area` entries keeping first instance  \n",
    "\n",
    "**Test output**:  \n",
    " Dataframe now contains 50 rows all with date 1999-12-*01* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "OQ8T0tYVQj74",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>city of london</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>33020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48922</td>\n",
       "      <td>0</td>\n",
       "      <td>6581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23128</td>\n",
       "      <td>8</td>\n",
       "      <td>313469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>bexley</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21386</td>\n",
       "      <td>18</td>\n",
       "      <td>217458.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E09000005</td>\n",
       "      <td>brent</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18532.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20911</td>\n",
       "      <td>6</td>\n",
       "      <td>260317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E09000006</td>\n",
       "      <td>bromley</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16720.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21293</td>\n",
       "      <td>13</td>\n",
       "      <td>294902.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E09000007</td>\n",
       "      <td>camden</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>23677.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30249</td>\n",
       "      <td>13</td>\n",
       "      <td>190003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E09000008</td>\n",
       "      <td>croydon</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19563.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22205</td>\n",
       "      <td>13</td>\n",
       "      <td>332066.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E09000009</td>\n",
       "      <td>ealing</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>20580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25046</td>\n",
       "      <td>12</td>\n",
       "      <td>302252.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E09000010</td>\n",
       "      <td>enfield</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19289.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21006</td>\n",
       "      <td>9</td>\n",
       "      <td>272731.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E09000011</td>\n",
       "      <td>greenwich</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21236.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22263</td>\n",
       "      <td>4</td>\n",
       "      <td>212168.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E09000012</td>\n",
       "      <td>hackney</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>23249.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39629</td>\n",
       "      <td>2</td>\n",
       "      <td>199087.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E09000013</td>\n",
       "      <td>hammersmith and fulham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28555</td>\n",
       "      <td>7</td>\n",
       "      <td>160634.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E09000014</td>\n",
       "      <td>haringey</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18783.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21683</td>\n",
       "      <td>5</td>\n",
       "      <td>218559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E09000015</td>\n",
       "      <td>harrow</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>20596.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22824</td>\n",
       "      <td>10</td>\n",
       "      <td>207909.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E09000016</td>\n",
       "      <td>havering</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17165.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18786</td>\n",
       "      <td>8</td>\n",
       "      <td>225712.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E09000017</td>\n",
       "      <td>hillingdon</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>24002.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28854</td>\n",
       "      <td>11</td>\n",
       "      <td>245053.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E09000018</td>\n",
       "      <td>hounslow</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>20155.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24602</td>\n",
       "      <td>14</td>\n",
       "      <td>214298.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E09000019</td>\n",
       "      <td>islington</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>25113.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34180</td>\n",
       "      <td>2</td>\n",
       "      <td>175717.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E09000020</td>\n",
       "      <td>kensington and chelsea</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>20646.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28074</td>\n",
       "      <td>13</td>\n",
       "      <td>147678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>E09000021</td>\n",
       "      <td>kingston upon thames</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19302.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22967</td>\n",
       "      <td>18</td>\n",
       "      <td>146003.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>E09000022</td>\n",
       "      <td>lambeth</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>23151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27930</td>\n",
       "      <td>8</td>\n",
       "      <td>266817.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>E09000023</td>\n",
       "      <td>lewisham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>20580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23283</td>\n",
       "      <td>4</td>\n",
       "      <td>250310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>E09000024</td>\n",
       "      <td>merton</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18962.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21867</td>\n",
       "      <td>11</td>\n",
       "      <td>185062.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>E09000025</td>\n",
       "      <td>newham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18862.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20580</td>\n",
       "      <td>3</td>\n",
       "      <td>240517.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>E09000026</td>\n",
       "      <td>redbridge</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19580.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22087</td>\n",
       "      <td>8</td>\n",
       "      <td>238138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>E09000027</td>\n",
       "      <td>richmond upon thames</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>22321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25832</td>\n",
       "      <td>na</td>\n",
       "      <td>172782.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>E09000028</td>\n",
       "      <td>southwark</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>22784.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26994</td>\n",
       "      <td>3</td>\n",
       "      <td>247853.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>E09000029</td>\n",
       "      <td>sutton</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19582.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22725</td>\n",
       "      <td>27</td>\n",
       "      <td>179375.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>E09000030</td>\n",
       "      <td>tower hamlets</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>26376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37524</td>\n",
       "      <td>3</td>\n",
       "      <td>193507.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>E09000031</td>\n",
       "      <td>waltham forest</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18547.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19888</td>\n",
       "      <td>9</td>\n",
       "      <td>221057.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>E09000032</td>\n",
       "      <td>wandsworth</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21321.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24707</td>\n",
       "      <td>7</td>\n",
       "      <td>264220.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>E09000033</td>\n",
       "      <td>westminster</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>24447.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36167</td>\n",
       "      <td>7</td>\n",
       "      <td>189233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>E12000001</td>\n",
       "      <td>north east</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16282.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18351</td>\n",
       "      <td>5</td>\n",
       "      <td>2550314.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>E12000002</td>\n",
       "      <td>north west</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16977.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19609</td>\n",
       "      <td>7</td>\n",
       "      <td>6773115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>E12000003</td>\n",
       "      <td>yorkshire and the humber</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16527.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18977</td>\n",
       "      <td>7</td>\n",
       "      <td>4956325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>E12000004</td>\n",
       "      <td>east midlands</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16392.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18864</td>\n",
       "      <td>11</td>\n",
       "      <td>4152443.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>E12000005</td>\n",
       "      <td>west midlands</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19686</td>\n",
       "      <td>9</td>\n",
       "      <td>5271959.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>E12000006</td>\n",
       "      <td>east</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20866</td>\n",
       "      <td>14</td>\n",
       "      <td>5338722.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>E12000007</td>\n",
       "      <td>london</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>22487.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29640</td>\n",
       "      <td>9</td>\n",
       "      <td>7153912.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>E12000008</td>\n",
       "      <td>south east</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18737.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22361</td>\n",
       "      <td>15</td>\n",
       "      <td>7955124.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>E12000009</td>\n",
       "      <td>south west</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16727.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19203</td>\n",
       "      <td>14</td>\n",
       "      <td>4880958.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>E13000001</td>\n",
       "      <td>inner london</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2750716.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>E13000002</td>\n",
       "      <td>outer london</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4403196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>E92000001</td>\n",
       "      <td>england</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17939.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21561</td>\n",
       "      <td>10</td>\n",
       "      <td>49032872.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>K02000001</td>\n",
       "      <td>united kingdom</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17803.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58684427.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>K03000001</td>\n",
       "      <td>great britain</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17866.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57005421.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>K04000001</td>\n",
       "      <td>england and wales</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>17974.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51933471.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>N92000002</td>\n",
       "      <td>northern ireland</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>15798.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1679006.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>S92000003</td>\n",
       "      <td>scotland</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16914.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5071950.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>W92000004</td>\n",
       "      <td>wales</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>16457.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2900599.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         code                      area        date  median_salary  \\\n",
       "0   E09000001            city of london  1999-12-01        33020.0   \n",
       "1   E09000002      barking and dagenham  1999-12-01        21480.0   \n",
       "2   E09000003                    barnet  1999-12-01        19568.0   \n",
       "3   E09000004                    bexley  1999-12-01        18621.0   \n",
       "4   E09000005                     brent  1999-12-01        18532.0   \n",
       "5   E09000006                   bromley  1999-12-01        16720.0   \n",
       "6   E09000007                    camden  1999-12-01        23677.0   \n",
       "7   E09000008                   croydon  1999-12-01        19563.0   \n",
       "8   E09000009                    ealing  1999-12-01        20580.0   \n",
       "9   E09000010                   enfield  1999-12-01        19289.0   \n",
       "10  E09000011                 greenwich  1999-12-01        21236.0   \n",
       "11  E09000012                   hackney  1999-12-01        23249.0   \n",
       "12  E09000013    hammersmith and fulham  1999-12-01        25000.0   \n",
       "13  E09000014                  haringey  1999-12-01        18783.0   \n",
       "14  E09000015                    harrow  1999-12-01        20596.0   \n",
       "15  E09000016                  havering  1999-12-01        17165.0   \n",
       "16  E09000017                hillingdon  1999-12-01        24002.0   \n",
       "17  E09000018                  hounslow  1999-12-01        20155.0   \n",
       "18  E09000019                 islington  1999-12-01        25113.0   \n",
       "19  E09000020    kensington and chelsea  1999-12-01        20646.0   \n",
       "20  E09000021      kingston upon thames  1999-12-01        19302.0   \n",
       "21  E09000022                   lambeth  1999-12-01        23151.0   \n",
       "22  E09000023                  lewisham  1999-12-01        20580.0   \n",
       "23  E09000024                    merton  1999-12-01        18962.0   \n",
       "24  E09000025                    newham  1999-12-01        18862.0   \n",
       "25  E09000026                 redbridge  1999-12-01        19580.0   \n",
       "26  E09000027      richmond upon thames  1999-12-01        22321.0   \n",
       "27  E09000028                 southwark  1999-12-01        22784.0   \n",
       "28  E09000029                    sutton  1999-12-01        19582.0   \n",
       "29  E09000030             tower hamlets  1999-12-01        26376.0   \n",
       "30  E09000031            waltham forest  1999-12-01        18547.0   \n",
       "31  E09000032                wandsworth  1999-12-01        21321.0   \n",
       "32  E09000033               westminster  1999-12-01        24447.0   \n",
       "33  E12000001                north east  1999-12-01        16282.0   \n",
       "34  E12000002                north west  1999-12-01        16977.0   \n",
       "35  E12000003  yorkshire and the humber  1999-12-01        16527.0   \n",
       "36  E12000004             east midlands  1999-12-01        16392.0   \n",
       "37  E12000005             west midlands  1999-12-01        17000.0   \n",
       "38  E12000006                      east  1999-12-01        18000.0   \n",
       "39  E12000007                    london  1999-12-01        22487.0   \n",
       "40  E12000008                south east  1999-12-01        18737.0   \n",
       "41  E12000009                south west  1999-12-01        16727.0   \n",
       "42  E13000001              inner london  1999-12-01            NaN   \n",
       "43  E13000002              outer london  1999-12-01            NaN   \n",
       "44  E92000001                   england  1999-12-01        17939.0   \n",
       "45  K02000001            united kingdom  1999-12-01        17803.0   \n",
       "46  K03000001             great britain  1999-12-01        17866.0   \n",
       "47  K04000001         england and wales  1999-12-01        17974.0   \n",
       "48  N92000002          northern ireland  1999-12-01        15798.0   \n",
       "49  S92000003                  scotland  1999-12-01        16914.0   \n",
       "50  W92000004                     wales  1999-12-01        16457.0   \n",
       "\n",
       "    life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "0                 NaN       48922             0           6581.0   \n",
       "1                 NaN       23620             3         162444.0   \n",
       "2                 NaN       23128             8         313469.0   \n",
       "3                 NaN       21386            18         217458.0   \n",
       "4                 NaN       20911             6         260317.0   \n",
       "5                 NaN       21293            13         294902.0   \n",
       "6                 NaN       30249            13         190003.0   \n",
       "7                 NaN       22205            13         332066.0   \n",
       "8                 NaN       25046            12         302252.0   \n",
       "9                 NaN       21006             9         272731.0   \n",
       "10                NaN       22263             4         212168.0   \n",
       "11                NaN       39629             2         199087.0   \n",
       "12                NaN       28555             7         160634.0   \n",
       "13                NaN       21683             5         218559.0   \n",
       "14                NaN       22824            10         207909.0   \n",
       "15                NaN       18786             8         225712.0   \n",
       "16                NaN       28854            11         245053.0   \n",
       "17                NaN       24602            14         214298.0   \n",
       "18                NaN       34180             2         175717.0   \n",
       "19                NaN       28074            13         147678.0   \n",
       "20                NaN       22967            18         146003.0   \n",
       "21                NaN       27930             8         266817.0   \n",
       "22                NaN       23283             4         250310.0   \n",
       "23                NaN       21867            11         185062.0   \n",
       "24                NaN       20580             3         240517.0   \n",
       "25                NaN       22087             8         238138.0   \n",
       "26                NaN       25832            na         172782.0   \n",
       "27                NaN       26994             3         247853.0   \n",
       "28                NaN       22725            27         179375.0   \n",
       "29                NaN       37524             3         193507.0   \n",
       "30                NaN       19888             9         221057.0   \n",
       "31                NaN       24707             7         264220.0   \n",
       "32                NaN       36167             7         189233.0   \n",
       "33                NaN       18351             5        2550314.0   \n",
       "34                NaN       19609             7        6773115.0   \n",
       "35                NaN       18977             7        4956325.0   \n",
       "36                NaN       18864            11        4152443.0   \n",
       "37                NaN       19686             9        5271959.0   \n",
       "38                NaN       20866            14        5338722.0   \n",
       "39                NaN       29640             9        7153912.0   \n",
       "40                NaN       22361            15        7955124.0   \n",
       "41                NaN       19203            14        4880958.0   \n",
       "42                NaN           -           NaN        2750716.0   \n",
       "43                NaN           -           NaN        4403196.0   \n",
       "44                NaN       21561            10       49032872.0   \n",
       "45                NaN       21314           NaN       58684427.0   \n",
       "46                NaN       21379           NaN       57005421.0   \n",
       "47                NaN       21549           NaN       51933471.0   \n",
       "48                NaN       19093           NaN        1679006.0   \n",
       "49                NaN       19667           NaN        5071950.0   \n",
       "50                NaN       18486           NaN        2900599.0   \n",
       "\n",
       "    number_of_jobs  area_size  no_of_houses  borough_flag  \n",
       "0              NaN        NaN           NaN             1  \n",
       "1              NaN        NaN           NaN             1  \n",
       "2              NaN        NaN           NaN             1  \n",
       "3              NaN        NaN           NaN             1  \n",
       "4              NaN        NaN           NaN             1  \n",
       "5              NaN        NaN           NaN             1  \n",
       "6              NaN        NaN           NaN             1  \n",
       "7              NaN        NaN           NaN             1  \n",
       "8              NaN        NaN           NaN             1  \n",
       "9              NaN        NaN           NaN             1  \n",
       "10             NaN        NaN           NaN             1  \n",
       "11             NaN        NaN           NaN             1  \n",
       "12             NaN        NaN           NaN             1  \n",
       "13             NaN        NaN           NaN             1  \n",
       "14             NaN        NaN           NaN             1  \n",
       "15             NaN        NaN           NaN             1  \n",
       "16             NaN        NaN           NaN             1  \n",
       "17             NaN        NaN           NaN             1  \n",
       "18             NaN        NaN           NaN             1  \n",
       "19             NaN        NaN           NaN             1  \n",
       "20             NaN        NaN           NaN             1  \n",
       "21             NaN        NaN           NaN             1  \n",
       "22             NaN        NaN           NaN             1  \n",
       "23             NaN        NaN           NaN             1  \n",
       "24             NaN        NaN           NaN             1  \n",
       "25             NaN        NaN           NaN             1  \n",
       "26             NaN        NaN           NaN             1  \n",
       "27             NaN        NaN           NaN             1  \n",
       "28             NaN        NaN           NaN             1  \n",
       "29             NaN        NaN           NaN             1  \n",
       "30             NaN        NaN           NaN             1  \n",
       "31             NaN        NaN           NaN             1  \n",
       "32             NaN        NaN           NaN             1  \n",
       "33             NaN        NaN           NaN             0  \n",
       "34             NaN        NaN           NaN             0  \n",
       "35             NaN        NaN           NaN             0  \n",
       "36             NaN        NaN           NaN             0  \n",
       "37             NaN        NaN           NaN             0  \n",
       "38             NaN        NaN           NaN             0  \n",
       "39             NaN        NaN           NaN             0  \n",
       "40             NaN        NaN           NaN             0  \n",
       "41             NaN        NaN           NaN             0  \n",
       "42             NaN        NaN           NaN             0  \n",
       "43             NaN        NaN           NaN             0  \n",
       "44             NaN        NaN           NaN             0  \n",
       "45             NaN        NaN           NaN             0  \n",
       "46             NaN        NaN           NaN             0  \n",
       "47             NaN        NaN           NaN             0  \n",
       "48             NaN        NaN           NaN             0  \n",
       "49             NaN        NaN           NaN             0  \n",
       "50             NaN        NaN           NaN             0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.drop_duplicates(subset = ['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQ_tQG_3WBXn"
   },
   "source": [
    "# Normalising Data  \n",
    "When we normalise data, we remodel a numeric column in a dataframe to be on a standard scale (e.g. 0 or 1).   \n",
    "\n",
    "For example if we had a column of BMI scores, we could normalise that column so that all scores greater than or equal to 25 were recoded to the value 1 (bad) and all scores less than 25 were recoded to 0 (good).  \n",
    "\n",
    "To normalise we need to:\n",
    "*   write a function, with the dataframe as a parameter, which will look at each row in dataframe column and return either a value in the normalised scale (e.g. 0,1 or 1,2,3,4) depending on that value.\n",
    "\n",
    "For example:  \n",
    "```\n",
    "def normalise_bmi(df):\n",
    "  if df['bmi'] >= 25:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "df[\"bmi\"] = df.apply(normalise_bmi, axis=1)\n",
    "```\n",
    "This code reassigns the values in the column \"bmi\" by sending each row one after the other to the normalise_bmi function, which will check the value in the \"bmi\" column and return either 0 or 1 depending on the value in the \"bmi\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8KPmy2_NVh1"
   },
   "source": [
    "### Exercise 7 - normalise data set\n",
    "---\n",
    "\n",
    "Create a function called **normalise_income(df)** that will return the values 1, 2 or 3 to represent low income, middle income and high income.  If the value in `df['median_salary']` is less than 27441 (the median), return 1, otherwise if it is less than 30932 (the upper quartile) return 2 and otherwise return 3.\n",
    "\n",
    "Apply the normalise_income(df) function to the `median_salary` column.\n",
    "\n",
    "*NOTE:  this operation will change the original dataframe so if you run it twice, everything in the median_salary column will change to 1 (as it had already been reduced to 1, 2 or 3 - if this happens, run the code in Exercise 4 again to get the original data again from the file.*\n",
    "\n",
    "**Test output**:  \n",
    "The maximum value of the column df['median_salary'] will be 3 and the minimum value will be 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>median_salary</th>\n",
       "      <th>life_satisfaction</th>\n",
       "      <th>mean_salary</th>\n",
       "      <th>recycling_pct</th>\n",
       "      <th>population_size</th>\n",
       "      <th>number_of_jobs</th>\n",
       "      <th>area_size</th>\n",
       "      <th>no_of_houses</th>\n",
       "      <th>borough_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E09000001</td>\n",
       "      <td>city of london</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>33020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48922</td>\n",
       "      <td>0</td>\n",
       "      <td>6581.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E09000002</td>\n",
       "      <td>barking and dagenham</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>21480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23620</td>\n",
       "      <td>3</td>\n",
       "      <td>162444.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E09000003</td>\n",
       "      <td>barnet</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>19568.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23128</td>\n",
       "      <td>8</td>\n",
       "      <td>313469.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E09000004</td>\n",
       "      <td>bexley</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18621.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21386</td>\n",
       "      <td>18</td>\n",
       "      <td>217458.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E09000005</td>\n",
       "      <td>brent</td>\n",
       "      <td>1999-12-01</td>\n",
       "      <td>18532.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20911</td>\n",
       "      <td>6</td>\n",
       "      <td>260317.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code                  area        date  median_salary  \\\n",
       "0  E09000001        city of london  1999-12-01        33020.0   \n",
       "1  E09000002  barking and dagenham  1999-12-01        21480.0   \n",
       "2  E09000003                barnet  1999-12-01        19568.0   \n",
       "3  E09000004                bexley  1999-12-01        18621.0   \n",
       "4  E09000005                 brent  1999-12-01        18532.0   \n",
       "\n",
       "   life_satisfaction mean_salary recycling_pct  population_size  \\\n",
       "0                NaN       48922             0           6581.0   \n",
       "1                NaN       23620             3         162444.0   \n",
       "2                NaN       23128             8         313469.0   \n",
       "3                NaN       21386            18         217458.0   \n",
       "4                NaN       20911             6         260317.0   \n",
       "\n",
       "   number_of_jobs  area_size  no_of_houses  borough_flag  \n",
       "0             NaN        NaN           NaN             1  \n",
       "1             NaN        NaN           NaN             1  \n",
       "2             NaN        NaN           NaN             1  \n",
       "3             NaN        NaN           NaN             1  \n",
       "4             NaN        NaN           NaN             1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "ktylpCl7QjGJ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       3\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "1066    2\n",
      "1067    2\n",
      "1068    1\n",
      "1069    2\n",
      "1070    2\n",
      "Name: median_salary, Length: 1071, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def normalise_income(housing):\n",
    "    if housing['median_salary'] < 27441.0:\n",
    "        return 1\n",
    "    elif housing['median_salary'] < 30932.0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "housing[\"median_salary\"] = housing.apply(normalise_income, axis=1)\n",
    "print(housing[\"median_salary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCrIEyMjSYTI"
   },
   "source": [
    "### Exercise 8 - normalise the number of jobs column\n",
    "---\n",
    "\n",
    "Using what you have learnt from Exercise 7:  \n",
    "*  use `df.describe()` to find the median, upper quartile and maximum for the number_of_jobs column  \n",
    "*  create a function called **normalise_jobs(df)** that will return 1 if the `number_of_jobs` is below the median, 2 if the `number_of_jobs` is below the upper quartile or 3 otherwise.\n",
    "*  normalise the `number_of_jobs` column by applying the function `normalise_jobs`.\n",
    "\n",
    "**Test output**:  \n",
    "The maximum value of the column df['number_of_jobs'] will be 3 and the minimum value will be 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    9.310000e+02\n",
       "mean     3.188095e+06\n",
       "std      8.058302e+06\n",
       "min      4.700000e+04\n",
       "25%      9.450000e+04\n",
       "50%      1.570000e+05\n",
       "75%      2.217000e+06\n",
       "max      3.575000e+07\n",
       "Name: number_of_jobs, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['number_of_jobs'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "giYXovr-T7TB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def normalise_jobs(housing):\n",
    "    if housing['number_of_jobs'] < 1.570000e+05:\n",
    "        return 1\n",
    "    elif housing['number_of_jobs'] < 2.217000e+06:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "housing['number_of_jobs'] = housing.apply(normalise_jobs, axis=1)\n",
    "print(housing['number_of_jobs'].min())\n",
    "print(housing['number_of_jobs'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-akqnUbYVblH"
   },
   "source": [
    "## Exercise 9 - normalise into a new column\n",
    "---\n",
    "\n",
    "Create a new function and code to normalise the `no_of_houses` column BUT this time, instead of assigning the result to `df['no_of_houses']` assign it to a new column called `df['housing_volume']`\n",
    "\n",
    "**Test output**:  \n",
    "The maximum value of the column df['housing_volume'] will be 3 and the minimum value will be 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "def normalise_housing(housing):\n",
    "    if housing['no_of_houses'] < 1.262760e+05:\n",
    "        return 1\n",
    "    elif housing['no_of_houses'] < 8.814682e+05:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "housing['housing_volume'] = housing.loc[:, 'no_of_houses']\n",
    "housing['housing_volume'] = housing.apply(normalise_housing, axis=1)\n",
    "print(housing['housing_volume'].min())\n",
    "print(housing['housing_volume'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_FaL31EXHZX"
   },
   "source": [
    "### Exercise 10 - normalise boroughs\n",
    "---\n",
    "\n",
    "Normalise the `area_size` column so that all values below mean are represented as 0 and otherwise are 1.  Assign the output to a new column called `area_size_normalised`.  \n",
    "\n",
    "**Test output**:  \n",
    "`area_size_normalised` column will contain both 0s and 1s.  The position of the first row with value 1 will be 0 and the position of the first row with value 0 will be 102.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "doIZ9M0UXkkv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.660000e+02\n",
       "mean     3.724903e+05\n",
       "std      2.157060e+06\n",
       "min      3.150000e+02\n",
       "25%      2.960000e+03\n",
       "50%      4.323000e+03\n",
       "75%      8.220000e+03\n",
       "max      1.330373e+07\n",
       "Name: area_size, dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing['area_size'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "housing['area_size_normalised'] = housing.loc[:, 'area_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def normalise_housing(housing):\n",
    "    if housing['area_size'] < 3.724903e+05:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "housing['area_size_normalised'] = housing.apply(normalise_housing, axis=1)\n",
    "print(housing['area_size_normalised'].iloc[0])\n",
    "print(housing['area_size_normalised'].iloc[102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Sorting_and_cleaning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
